---
title: "Homework 6"
author: "Chufeng Yang"
date: '`r format(Sys.time(), "%Y-%m-%d")`'
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(viridis)
library(modelr)
library(mgcv)
library(tidyverse)
library(modelr)
library(p8105.datasets)
knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
theme_set(theme_minimal() + theme(legend.position = "bottom"))
```


### Problem 1

```{r}
homicide_df = 
  read_csv("data/homicide-data.csv", na = c("", "NA", "Unknown")) %>% 
  mutate(
    city_state = str_c(city, state, sep = ", "),
    victim_age = as.numeric(victim_age),
    resolution = case_when(
      disposition == "Closed without arrest" ~ 0,
      disposition == "Open/No arrest"        ~ 0,
      disposition == "Closed by arrest"      ~ 1)
  ) %>% 
  filter(
    victim_race %in% c("White", "Black"),
    city_state != "Tulsa, AL") %>% 
  select(city_state, resolution, victim_age, victim_race, victim_sex)
```


Start with one city.

```{r}
baltimore_df =
  homicide_df %>% 
  filter(city_state == "Baltimore, MD")
glm(resolution ~ victim_age + victim_race + victim_sex, 
    data = baltimore_df,
    family = binomial()) %>% 
  broom::tidy() %>% 
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)
  ) %>% 
  select(term, OR, starts_with("CI")) %>% 
  knitr::kable(digits = 3)
```


Run `glm` for each of the cities in the dataset.
And extract the adjusted odds ratio (and CI) for solving homicides comparing Black victims to white victims.

```{r}
models_results_df = 
  homicide_df %>% 
  nest(data = -city_state) %>% 
  mutate(
    models = 
      map(.x = data, ~glm(resolution ~ victim_age + victim_race + victim_sex, data = .x, family = binomial())),
    results = map(models, broom::tidy)
  ) %>% 
  select(city_state, results) %>% 
  unnest(results) %>% 
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)
  ) %>% 
  select(city_state, term, OR, starts_with("CI"))  %>% 
  filter(term == "victim_raceWhite")
```

Create a plot that shows the estimated ORs and CIs for each city. 

```{r}
models_results_df %>% 
  mutate(city_state = fct_reorder(city_state, OR)) %>% 
  ggplot(aes(x = city_state, y = OR)) + 
  geom_point() + 
  geom_errorbar(aes(ymin = CI_lower, ymax = CI_upper)) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  scale_y_continuous(limits=c(0,30), breaks=1)
```
We could find the estimated ORs and CIs for each city. And some of them, like Albuquerque,NM or Stockton,CA, have relatively larger OR and wider CI. Moreover, we could find that altought most of our estimated ORs are pretty close to 1,there are more ORs' point estimates are greater than 1, which means that when comparing Black victims to white victims, homicides of white victims are more likely results in arrest. When looking and CIs, some(like a half) are above 1, which means for these cities, we might can conclude that homicides of white victims are more likely results in arrest.


## Problem 2

### Load and clean the data for regression analysis

```{r message=FALSE}
baby_df = 
  read_csv("./data/birthweight.csv") %>% 
  mutate(
    babysex = factor(case_when(
      babysex == 1 ~ "male",
      babysex == 2 ~ "female"
      )),
    frace = factor(case_when(
      frace == 1 ~ "White",
      frace == 2 ~ "Black",
      frace == 3 ~ "Asian",
      frace == 4 ~ "Puerto Rican",
      frace == 8 ~ "Other"
    )),
    malform = factor(case_when(
      malform == 0 ~ "absent",
      malform == 1 ~ "present"
      )),
    mrace = factor(case_when(
      mrace == 1 ~ "White",
      mrace == 2 ~ "Black",
      mrace == 3 ~ "Asian",
      mrace == 4 ~ "Puerto Rican",
      mrace == 8 ~ "Other"
    ))
  )
```

### Take a look on all variables:
```{r}
baby_df %>% 
  lm(bwt~.,data = .) %>% 
  broom::tidy() 
```


### Propose a regression model for birthweight
Personally, I would like to select the model based on a data-driven model-building process.  

Given that I have never contacted with such kind of research, I choose to apply the backward stepwise regression, which uses AIC criterion for variable selection.

```{r results='hide'}
mult.fit = lm(bwt ~ .,data = baby_df)
step(mult.fit, direction='backward')
# Code result has been hidden in output file
```

The result of backward stepwise regression provide these variables:  
babysex, bhead, blength, delwt, fincome, gaweeks,  mheight, mrace, parity, ppwt, smoken    
Thus, I will take this variables as potential predictors.

My regression model:
```{r}
fit_model = lm(formula = bwt ~ babysex + bhead + blength + delwt + fincome + gaweeks + mheight + mrace + parity + ppwt + smoken, data = baby_df)
```

Add residuals and predictions 
```{r}
fit_df = 
  baby_df %>%  
  modelr::add_residuals(fit_model) %>% 
  modelr::add_predictions(fit_model)
```

Create a plot of model residuals against fitted values
```{r}
fit_df %>% 
  ggplot(aes(x = pred, y = resid)) + 
  geom_point(alpha = 0.3) +
  geom_smooth(method = "lm", color = "red", linetype = 2) + 
  labs(
    title = "Plot of model residuals against fitted values",
    x = "Predictions",
    y = "Residuals"
  )
```
  
\ From the plot above, we could find that residuals of our model are basically symmetrically gathered around 0. But when predictions are relatively lower, there would be larger residuals. Meanwhile, we could see that the predictions are not symmetrically distributed but more like a left-skewed distribution, and even have some abnormal values(such as predictions lower than 0), which might indicate the problems in the model.

### Compare my model to two others

Comparing models:
model 1:
```{r}
model_1 = lm(bwt ~ blength + gaweeks, data = baby_df)
model_1 %>% 
  broom::tidy() %>% 
  select(term, estimate, p.value) %>% 
  knitr::kable()
```

Model 2:
```{r}
model_2 = lm(bwt ~ bhead * blength * babysex, data = baby_df)
model_2 %>% 
  broom::tidy() %>% 
  select(term, estimate, p.value) %>% 
  knitr::kable()
```

Cross Validation
```{r}
cv_df =
  crossv_mc(baby_df, 200) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))
```

```{r}
cv_df = 
  cv_df %>% 
  mutate(
    fit_model  = map(train, ~lm(bwt ~ babysex + bhead + blength + delwt + fincome + 
    gaweeks + mheight + mrace + parity + ppwt + smoken, data = .x)),
    model_1  = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
    model_2  = map(train, ~gam(bwt ~ bhead * blength * babysex, data = as_tibble(.x)))) %>% 
  mutate(
    rmse_fit_model  = map2_dbl(fit_model, test, ~rmse(model = .x, data = .y)),
    rmse_model_1  = map2_dbl(model_1, test, ~rmse(model = .x, data = .y)),
    rmse_model_2  = map2_dbl(model_2, test, ~rmse(model = .x, data = .y)))
```

Make a plot to show the result
```{r}
cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```

\ From the plot, we could find that our model has lowest rmse, which means that it could be the best model among these three models, and the model 2(using head circumference, length, sex) is better than model 3(sing length at birth and gestational age as predictors). However, the rmse value of all these three model are relatively high(rmse > 200), might indicate that all of them are not optimal model to predict baby’s birth weight.


## Problem 3

### Get data

```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```

### Bootstrap
```{r}
set.seed(1)
bootstrap_results = weather_df %>% 
  modelr::bootstrap(n = 5000) %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x) ),
    results = map(models, broom::tidy),
    results_glance = map(models, broom::glance)) %>% 
  unnest(results,results_glance) %>% 
  select(id = .id, term, estimate, r.squared) %>% 
  mutate(term = recode(term, '(Intercept)' = 'intercept'))
```


```{r}
bootstrap_results %>% 
  head() %>% 
  knitr::kable()
```

Plot the distribution of r^2
```{r}
bootstrap_results %>%
    ggplot(aes(x = r.squared)) +
  geom_density() +
  labs(
    title = "Distribution of r^2",
    x = "r^2",
    y = "Density"
  )
```

Calculate the log values
```{r}
log_df = bootstrap_results %>% 
  pivot_wider(
    names_from = term,
    values_from = estimate
  ) %>% 
  mutate(log_value = log(intercept*tmin))
```

Plot the distribution of log(β^0∗β^1)
```{r}
log_df %>% 
  ggplot(aes(x = log_value)) +
  geom_density() +
  labs(
        title = "Distribution of the log(^β0*^β1)",
        x = "log(^β0*^β1)",
        y = "Density"
    )
```

95% confidence interval for r^2 and log(β^0∗β^1)
 r^2
```{r}
bootstrap_results %>% group_by(term) %>% 
  summarize(
    ci_lower = quantile(r.squared, 0.025), 
    ci_upper = quantile(r.squared, 0.975))
```

log(β^0∗β^1)
```{r}
log_df %>% 
  summarize(
    ci_lower = quantile(r.squared, 0.025), 
    ci_upper = quantile(r.squared, 0.975))
```




